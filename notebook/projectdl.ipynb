{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Configuration\nclass Config:\n    # Paths (adjust these to your Kaggle paths)\n    DATA_DIR = '/kaggle/input/recursion-cellular-image-classification'\n    TRAIN_CSV = f'{DATA_DIR}/train.csv'\n    TEST_CSV = f'{DATA_DIR}/test.csv'\n    \n    # Model settings\n    MODEL_NAME = 'efficientnet_b3'  # Fast and accurate\n    IMG_SIZE = 320  # Reduced from 512 for speed\n    BATCH_SIZE = 32  # Adjust based on GPU memory\n    EPOCHS = 40  # Reduced for time\n    LR = 3e-4\n    \n    # Training settings\n    NUM_WORKERS = 2\n    SEED = 42\n    NUM_CLASSES = 1108\n    \n    # Use only HUVEC cell type for speed (you can add more if time permits)\n    CELL_TYPES = ['HUVEC']  # Add 'RPE', 'HEPG2', 'U2OS' if you have time\n    \n    # sirna needs to be converted to numeric labels\n    CONVERT_SIRNA = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:50:44.778460Z","iopub.execute_input":"2025-11-20T12:50:44.778748Z","iopub.status.idle":"2025-11-20T12:50:59.371744Z","shell.execute_reply.started":"2025-11-20T12:50:44.778725Z","shell.execute_reply":"2025-11-20T12:50:59.370977Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(Config.SEED)\n\n# Dataset class\nclass CellularDataset(Dataset):\n    def __init__(self, df, data_dir, mode='train', transform=None):\n        self.df = df\n        self.data_dir = data_dir\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def load_image(self, row):\n        \"\"\"Load 6-channel image\"\"\"\n        if self.mode == 'train':\n            exp = row['experiment']\n            plate = row['plate']\n            well = row['well']\n            site = row['site']\n            path_template = f'{self.data_dir}/train/{exp}/Plate{plate}/{well}_s{site}_w'\n        else:\n            img_id = row['id_code']\n            exp = row['experiment']\n            plate = row['plate']\n            well = row['well']\n            site = 1  # Test images are site 1\n            path_template = f'{self.data_dir}/test/{exp}/Plate{plate}/{well}_s{site}_w'\n        \n        # Load all 6 channels\n        channels = []\n        for i in range(1, 7):\n            img_path = f'{path_template}{i}.png'\n            if os.path.exists(img_path):\n                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n                channels.append(img)\n            else:\n                # Fallback if file doesn't exist\n                channels.append(np.zeros((512, 512), dtype=np.uint8))\n        \n        # Stack channels and resize\n        img = np.stack(channels, axis=-1)\n        img = cv2.resize(img, (Config.IMG_SIZE, Config.IMG_SIZE))\n        \n        return img\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = self.load_image(row)\n        \n        # Normalize to [0, 1]\n        img = img.astype(np.float32) / 255.0\n        \n        if self.transform:\n            # Convert to PIL for transforms (handle 6 channels)\n            img = torch.from_numpy(img).permute(2, 0, 1)  # C, H, W\n        else:\n            img = torch.from_numpy(img).permute(2, 0, 1)\n        \n        if self.mode == 'train':\n            label = row['label']\n            return img, label\n        else:\n            return img, row['id_code']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:51:11.215154Z","iopub.execute_input":"2025-11-20T12:51:11.215640Z","iopub.status.idle":"2025-11-20T12:51:11.434250Z","shell.execute_reply.started":"2025-11-20T12:51:11.215618Z","shell.execute_reply":"2025-11-20T12:51:11.433453Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CellularModel(nn.Module):\n    def __init__(self, model_name, num_classes, in_channels=6):\n        super().__init__()\n        # Load pretrained model\n        self.backbone = timm.create_model(model_name, pretrained=True, in_chans=3)\n        \n        # Modify first conv layer to accept 6 channels\n        if hasattr(self.backbone, 'conv_stem'):\n            old_conv = self.backbone.conv_stem\n            self.backbone.conv_stem = nn.Conv2d(\n                in_channels, old_conv.out_channels,\n                kernel_size=old_conv.kernel_size,\n                stride=old_conv.stride,\n                padding=old_conv.padding,\n                bias=False\n            )\n            # Initialize with average of pretrained weights\n            with torch.no_grad():\n                self.backbone.conv_stem.weight[:, :3] = old_conv.weight\n                self.backbone.conv_stem.weight[:, 3:] = old_conv.weight\n        \n        # Get number of features\n        n_features = self.backbone.get_classifier().in_features\n        self.backbone.reset_classifier(0)  # Remove classifier\n        \n        # Custom classifier\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(n_features, num_classes)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:51:33.048127Z","iopub.execute_input":"2025-11-20T12:51:33.048451Z","iopub.status.idle":"2025-11-20T12:51:33.055144Z","shell.execute_reply.started":"2025-11-20T12:51:33.048428Z","shell.execute_reply":"2025-11-20T12:51:33.054351Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(loader, desc='Training')\n    for imgs, labels in pbar:\n        imgs, labels = imgs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        pbar.set_postfix({'loss': running_loss/len(loader), 'acc': 100.*correct/total})\n    \n    return running_loss/len(loader), 100.*correct/total\n\n# Validation function\ndef validate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for imgs, labels in tqdm(loader, desc='Validation'):\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    return running_loss/len(loader), 100.*correct/total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:51:48.359962Z","iopub.execute_input":"2025-11-20T12:51:48.360741Z","iopub.status.idle":"2025-11-20T12:51:48.368077Z","shell.execute_reply.started":"2025-11-20T12:51:48.360714Z","shell.execute_reply":"2025-11-20T12:51:48.367343Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def main():\n    # Load data\n    print(\"Loading data...\")\n    train_df = pd.read_csv(Config.TRAIN_CSV)\n    test_df = pd.read_csv(Config.TEST_CSV)\n    \n    # Extract cell type from experiment column\n    train_df['cell_type'] = train_df['experiment'].str.split('-').str[0]\n    test_df['cell_type'] = test_df['experiment'].str.split('-').str[0]\n    \n    # Filter by cell type for speed\n    train_df = train_df[train_df['cell_type'].isin(Config.CELL_TYPES)].reset_index(drop=True)\n    test_df = test_df[test_df['cell_type'].isin(Config.CELL_TYPES)].reset_index(drop=True)\n    \n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Test samples: {len(test_df)}\")\n    print(f\"Cell types in train: {train_df['cell_type'].unique()}\")\n    \n    # Convert sirna labels to numeric (sirna_1 -> 1, sirna_10 -> 10, etc.)\n    train_df['sirna_id'] = train_df['sirna'].str.replace('sirna_', '').astype(int)\n    \n    # Create label mapping (need to map to 0-indexed consecutive integers)\n    unique_sirnas = sorted(train_df['sirna_id'].unique())\n    sirna_to_label = {sirna: idx for idx, sirna in enumerate(unique_sirnas)}\n    train_df['label'] = train_df['sirna_id'].map(sirna_to_label)\n    \n    print(f\"Number of unique sirnas: {len(unique_sirnas)}\")\n    print(f\"Label range: 0 to {train_df['label'].max()}\")\n    \n    # Update NUM_CLASSES based on actual data\n    Config.NUM_CLASSES = len(unique_sirnas)\n    \n    # Split train/val\n    train_data, val_data = train_test_split(train_df, test_size=0.15, random_state=Config.SEED, stratify=train_df['label'])\n    \n    # Create datasets\n    train_dataset = CellularDataset(train_data, Config.DATA_DIR, mode='train')\n    val_dataset = CellularDataset(val_data, Config.DATA_DIR, mode='train')\n    \n    # Create dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, \n                             shuffle=True, num_workers=Config.NUM_WORKERS, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, \n                           shuffle=False, num_workers=Config.NUM_WORKERS, pin_memory=True)\n    \n    # Create model\n    print(\"Creating model...\")\n    model = CellularModel(Config.MODEL_NAME, Config.NUM_CLASSES).to(device)\n    \n    # Loss and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS)\n    \n    # Training loop\n    best_acc = 0\n    for epoch in range(Config.EPOCHS):\n        print(f\"\\nEpoch {epoch+1}/{Config.EPOCHS}\")\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n        scheduler.step()\n        \n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_acc:\n            best_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f\"Saved best model with accuracy: {best_acc:.2f}%\")\n    \n    # Load best model for inference\n    print(\"\\nLoading best model for inference...\")\n    model.load_state_dict(torch.load('best_model.pth'))\n    \n    # Inference on test set\n    print(\"Generating predictions...\")\n    test_dataset = CellularDataset(test_df, Config.DATA_DIR, mode='test')\n    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, \n                            shuffle=False, num_workers=Config.NUM_WORKERS)\n    \n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for imgs, img_ids in tqdm(test_loader, desc='Inference'):\n            imgs = imgs.to(device)\n            outputs = model(imgs)\n            _, preds = outputs.max(1)\n            \n            predictions.extend(preds.cpu().numpy())\n            ids.extend(img_ids)\n    \n    # Convert predictions back to sirna format\n    label_to_sirna = {idx: sirna for sirna, idx in sirna_to_label.items()}\n    predictions_sirna = [label_to_sirna[pred] for pred in predictions]\n    \n    # Create submission\n    submission = pd.DataFrame({\n        'id_code': ids,\n        'sirna': predictions_sirna\n    })\n    submission.to_csv('submission.csv', index=False)\n    print(\"\\nSubmission saved to submission.csv\")\n    print(f\"Best validation accuracy: {best_acc:.2f}%\")\n    print(f\"Sample predictions:\")\n    print(submission.head(10))\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:52:14.508953Z","iopub.execute_input":"2025-11-20T12:52:14.509253Z","iopub.status.idle":"2025-11-20T12:52:16.764344Z","shell.execute_reply.started":"2025-11-20T12:52:14.509232Z","shell.execute_reply":"2025-11-20T12:52:16.762904Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nTraining samples: 17689\nTest samples: 8847\nCell types in train: ['HUVEC']\nNumber of unique sirnas: 1108\nLabel range: 0 to 1107\nCreating model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dada37582ef04d04af89cd4f7f853e86"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/470 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/1330529097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_48/1330529097.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEpoch {epoch+1}/{Config.EPOCHS}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/3736582298.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'site'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_48/1543366408.py\", line 55, in __getitem__\n    img = self.load_image(row)\n          ^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/1543366408.py\", line 26, in load_image\n    site = row['site']\n           ~~~^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\", line 1121, in __getitem__\n    return self._get_value(key)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\", line 1237, in _get_value\n    loc = self.index.get_loc(label)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'site'\n"],"ename":"KeyError","evalue":"Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'site'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipykernel_48/1543366408.py\", line 55, in __getitem__\n    img = self.load_image(row)\n          ^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_48/1543366408.py\", line 26, in load_image\n    site = row['site']\n           ~~~^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\", line 1121, in __getitem__\n    return self._get_value(key)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\", line 1237, in _get_value\n    loc = self.index.get_loc(label)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'site'\n","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSVs\nDATA_DIR = '/kaggle/input/recursion-cellular-image-classification'\ntrain_df = pd.read_csv(f'{DATA_DIR}/train.csv')\ntest_df = pd.read_csv(f'{DATA_DIR}/test.csv')\n\n# Print info about the dataframes\nprint(\"TRAIN CSV INFO:\")\nprint(train_df.head())\nprint(\"\\nTrain columns:\", train_df.columns.tolist())\nprint(\"Train shape:\", train_df.shape)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"\\nTEST CSV INFO:\")\nprint(test_df.head())\nprint(\"\\nTest columns:\", test_df.columns.tolist())\nprint(\"Test shape:\", test_df.shape)\n\n# Check unique values for some columns\nif 'experiment' in train_df.columns:\n    print(\"\\nUnique experiments:\", train_df['experiment'].unique())\nif 'plate' in train_df.columns:\n    print(\"Unique plates:\", train_df['plate'].nunique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:54:13.325646Z","iopub.execute_input":"2025-11-20T12:54:13.325938Z","iopub.status.idle":"2025-11-20T12:54:13.432108Z","shell.execute_reply.started":"2025-11-20T12:54:13.325917Z","shell.execute_reply":"2025-11-20T12:54:13.431359Z"}},"outputs":[{"name":"stdout","text":"TRAIN CSV INFO:\n          id_code experiment  plate well       sirna\n0  HEPG2-01_1_B03   HEPG2-01      1  B03   sirna_250\n1  HEPG2-01_1_B04   HEPG2-01      1  B04    sirna_62\n2  HEPG2-01_1_B05   HEPG2-01      1  B05  sirna_1115\n3  HEPG2-01_1_B06   HEPG2-01      1  B06   sirna_602\n4  HEPG2-01_1_B07   HEPG2-01      1  B07   sirna_529\n\nTrain columns: ['id_code', 'experiment', 'plate', 'well', 'sirna']\nTrain shape: (36517, 5)\n\n==================================================\n\nTEST CSV INFO:\n          id_code experiment  plate well\n0  HEPG2-08_1_B03   HEPG2-08      1  B03\n1  HEPG2-08_1_B04   HEPG2-08      1  B04\n2  HEPG2-08_1_B05   HEPG2-08      1  B05\n3  HEPG2-08_1_B06   HEPG2-08      1  B06\n4  HEPG2-08_1_B07   HEPG2-08      1  B07\n\nTest columns: ['id_code', 'experiment', 'plate', 'well']\nTest shape: (19899, 4)\n\nUnique experiments: ['HEPG2-01' 'HEPG2-02' 'HEPG2-03' 'HEPG2-04' 'HEPG2-05' 'HEPG2-06'\n 'HEPG2-07' 'HUVEC-01' 'HUVEC-02' 'HUVEC-03' 'HUVEC-04' 'HUVEC-05'\n 'HUVEC-06' 'HUVEC-07' 'HUVEC-08' 'HUVEC-09' 'HUVEC-10' 'HUVEC-11'\n 'HUVEC-12' 'HUVEC-13' 'HUVEC-14' 'HUVEC-15' 'HUVEC-16' 'RPE-01' 'RPE-02'\n 'RPE-03' 'RPE-04' 'RPE-05' 'RPE-06' 'RPE-07' 'U2OS-01' 'U2OS-02'\n 'U2OS-03']\nUnique plates: 4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport glob\n\n# Check one example to see the file structure\nsample = train_df.iloc[0]\nexp = sample['experiment']\nplate = sample['plate']\nwell = sample['well']\n\npath = f'/kaggle/input/recursion-cellular-image-classification/train/{exp}/Plate{plate}/'\nfiles = sorted(glob.glob(f'{path}{well}*.png'))\nprint(f\"Files for {well}:\")\nfor f in files[:10]:  # Show first 10\n    print(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:54:16.554012Z","iopub.execute_input":"2025-11-20T12:54:16.554344Z","iopub.status.idle":"2025-11-20T12:54:16.640608Z","shell.execute_reply.started":"2025-11-20T12:54:16.554294Z","shell.execute_reply":"2025-11-20T12:54:16.639913Z"}},"outputs":[{"name":"stdout","text":"Files for B03:\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s1_w1.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s1_w2.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s1_w3.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s1_w4.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s1_w5.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s1_w6.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s2_w1.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s2_w2.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s2_w3.png\n/kaggle/input/recursion-cellular-image-classification/train/HEPG2-01/Plate1/B03_s2_w4.png\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Recursion Cellular Image Classification - Quick Solution\n# Optimized for time constraints (< 10 hours)\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Configuration\nclass Config:\n    # Paths (adjust these to your Kaggle paths)\n    DATA_DIR = '/kaggle/input/recursion-cellular-image-classification'\n    TRAIN_CSV = f'{DATA_DIR}/train.csv'\n    TEST_CSV = f'{DATA_DIR}/test.csv'\n    \n    # Model settings\n    MODEL_NAME = 'efficientnet_b3'  # Fast and accurate\n    IMG_SIZE = 320  # Reduced from 512 for speed\n    BATCH_SIZE = 32  # Adjust based on GPU memory\n    EPOCHS = 40  # Reduced for time\n    LR = 3e-4\n    \n    # Training settings\n    NUM_WORKERS = 2\n    SEED = 42\n    NUM_CLASSES = 1108\n    \n    # Use only HUVEC cell type for speed (you can add more if time permits)\n    CELL_TYPES = ['HUVEC']  # Add 'RPE', 'HEPG2', 'U2OS' if you have time\n    \n    # sirna needs to be converted to numeric labels\n    CONVERT_SIRNA = True\n\n# Set seed\ndef set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(Config.SEED)\n\n# Dataset class\nclass CellularDataset(Dataset):\n    def __init__(self, df, data_dir, mode='train', transform=None):\n        self.df = df\n        self.data_dir = data_dir\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def load_image(self, row):\n        \"\"\"Load 6-channel image\"\"\"\n        exp = row['experiment']\n        plate = row['plate']\n        well = row['well']\n        \n        # Extract site from id_code (format: CELLTYPE-XX_PLATE_WELL_siteN)\n        # For train: HEPG2-01_1_B03 -> need to find the image files\n        # The site information is in the actual filename, not the CSV\n        # We need to try site 1 and site 2\n        \n        if self.mode == 'train':\n            path_template = f'{self.data_dir}/train/{exp}/Plate{plate}/{well}_s1_w'\n        else:\n            path_template = f'{self.data_dir}/test/{exp}/Plate{plate}/{well}_s1_w'\n        \n        # Load all 6 channels\n        channels = []\n        for i in range(1, 7):\n            img_path = f'{path_template}{i}.png'\n            if os.path.exists(img_path):\n                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n                channels.append(img)\n            else:\n                # Fallback if file doesn't exist\n                channels.append(np.zeros((512, 512), dtype=np.uint8))\n        \n        # Stack channels and resize\n        img = np.stack(channels, axis=-1)\n        img = cv2.resize(img, (Config.IMG_SIZE, Config.IMG_SIZE))\n        \n        return img\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = self.load_image(row)\n        \n        # Normalize to [0, 1]\n        img = img.astype(np.float32) / 255.0\n        \n        if self.transform:\n            # Convert to PIL for transforms (handle 6 channels)\n            img = torch.from_numpy(img).permute(2, 0, 1)  # C, H, W\n        else:\n            img = torch.from_numpy(img).permute(2, 0, 1)\n        \n        if self.mode == 'train':\n            label = row['label']\n            return img, label\n        else:\n            return img, row['id_code']\n\n# Model\nclass CellularModel(nn.Module):\n    def __init__(self, model_name, num_classes, in_channels=6):\n        super().__init__()\n        # Load pretrained model\n        self.backbone = timm.create_model(model_name, pretrained=True, in_chans=3)\n        \n        # Modify first conv layer to accept 6 channels\n        if hasattr(self.backbone, 'conv_stem'):\n            old_conv = self.backbone.conv_stem\n            self.backbone.conv_stem = nn.Conv2d(\n                in_channels, old_conv.out_channels,\n                kernel_size=old_conv.kernel_size,\n                stride=old_conv.stride,\n                padding=old_conv.padding,\n                bias=False\n            )\n            # Initialize with average of pretrained weights\n            with torch.no_grad():\n                self.backbone.conv_stem.weight[:, :3] = old_conv.weight\n                self.backbone.conv_stem.weight[:, 3:] = old_conv.weight\n        \n        # Get number of features\n        n_features = self.backbone.get_classifier().in_features\n        self.backbone.reset_classifier(0)  # Remove classifier\n        \n        # Custom classifier\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.3),\n            nn.Linear(n_features, num_classes)\n        )\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n\n# Training function\ndef train_epoch(model, loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(loader, desc='Training')\n    for imgs, labels in pbar:\n        imgs, labels = imgs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        pbar.set_postfix({'loss': running_loss/len(loader), 'acc': 100.*correct/total})\n    \n    return running_loss/len(loader), 100.*correct/total\n\n# Validation function\ndef validate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for imgs, labels in tqdm(loader, desc='Validation'):\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    return running_loss/len(loader), 100.*correct/total\n\n# Main training pipeline\ndef main():\n    # Load data\n    print(\"Loading data...\")\n    train_df = pd.read_csv(Config.TRAIN_CSV)\n    test_df = pd.read_csv(Config.TEST_CSV)\n    \n    # Extract cell type from experiment column\n    train_df['cell_type'] = train_df['experiment'].str.split('-').str[0]\n    test_df['cell_type'] = test_df['experiment'].str.split('-').str[0]\n    \n    # Filter by cell type for speed\n    train_df = train_df[train_df['cell_type'].isin(Config.CELL_TYPES)].reset_index(drop=True)\n    test_df = test_df[test_df['cell_type'].isin(Config.CELL_TYPES)].reset_index(drop=True)\n    \n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Test samples: {len(test_df)}\")\n    print(f\"Cell types in train: {train_df['cell_type'].unique()}\")\n    \n    # Convert sirna labels to numeric (sirna_1 -> 1, sirna_10 -> 10, etc.)\n    train_df['sirna_id'] = train_df['sirna'].str.replace('sirna_', '').astype(int)\n    \n    # Create label mapping (need to map to 0-indexed consecutive integers)\n    unique_sirnas = sorted(train_df['sirna_id'].unique())\n    sirna_to_label = {sirna: idx for idx, sirna in enumerate(unique_sirnas)}\n    train_df['label'] = train_df['sirna_id'].map(sirna_to_label)\n    \n    print(f\"Number of unique sirnas: {len(unique_sirnas)}\")\n    print(f\"Label range: 0 to {train_df['label'].max()}\")\n    \n    # Update NUM_CLASSES based on actual data\n    Config.NUM_CLASSES = len(unique_sirnas)\n    \n    # Split train/val\n    train_data, val_data = train_test_split(train_df, test_size=0.15, random_state=Config.SEED, stratify=train_df['label'])\n    \n    # Create datasets\n    train_dataset = CellularDataset(train_data, Config.DATA_DIR, mode='train')\n    val_dataset = CellularDataset(val_data, Config.DATA_DIR, mode='train')\n    \n    # Create dataloaders\n    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, \n                             shuffle=True, num_workers=Config.NUM_WORKERS, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, \n                           shuffle=False, num_workers=Config.NUM_WORKERS, pin_memory=True)\n    \n    # Create model\n    print(\"Creating model...\")\n    model = CellularModel(Config.MODEL_NAME, Config.NUM_CLASSES).to(device)\n    \n    # Loss and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-4)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.EPOCHS)\n    \n    # Training loop\n    best_acc = 0\n    for epoch in range(Config.EPOCHS):\n        print(f\"\\nEpoch {epoch+1}/{Config.EPOCHS}\")\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n        scheduler.step()\n        \n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_acc:\n            best_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f\"Saved best model with accuracy: {best_acc:.2f}%\")\n    \n    # Load best model for inference\n    print(\"\\nLoading best model for inference...\")\n    model.load_state_dict(torch.load('best_model.pth'))\n    \n    # Inference on test set\n    print(\"Generating predictions...\")\n    test_dataset = CellularDataset(test_df, Config.DATA_DIR, mode='test')\n    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, \n                            shuffle=False, num_workers=Config.NUM_WORKERS)\n    \n    model.eval()\n    predictions = []\n    ids = []\n    \n    with torch.no_grad():\n        for imgs, img_ids in tqdm(test_loader, desc='Inference'):\n            imgs = imgs.to(device)\n            outputs = model(imgs)\n            _, preds = outputs.max(1)\n            \n            predictions.extend(preds.cpu().numpy())\n            ids.extend(img_ids)\n    \n    # Convert predictions back to sirna format\n    label_to_sirna = {idx: sirna for sirna, idx in sirna_to_label.items()}\n    predictions_sirna = [label_to_sirna[pred] for pred in predictions]\n    \n    # Create submission\n    submission = pd.DataFrame({\n        'id_code': ids,\n        'sirna': predictions_sirna\n    })\n    submission.to_csv('submission.csv', index=False)\n    print(\"\\nSubmission saved to submission.csv\")\n    print(f\"Best validation accuracy: {best_acc:.2f}%\")\n    print(f\"Sample predictions:\")\n    print(submission.head(10))\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T12:55:15.214784Z","iopub.execute_input":"2025-11-20T12:55:15.215084Z","iopub.status.idle":"2025-11-20T17:56:53.812726Z","shell.execute_reply.started":"2025-11-20T12:55:15.215066Z","shell.execute_reply":"2025-11-20T17:56:53.811615Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading data...\nTraining samples: 17689\nTest samples: 8847\nCell types in train: ['HUVEC']\nNumber of unique sirnas: 1108\nLabel range: 0 to 1107\nCreating model...\n\nEpoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [12:53<00:00,  1.65s/it, loss=6.4, acc=1.84]   \nValidation: 100%|██████████| 83/83 [02:18<00:00,  1.67s/it]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 6.4036, Train Acc: 1.84%\nVal Loss: 5.1270, Val Acc: 8.21%\nSaved best model with accuracy: 8.21%\n\nEpoch 2/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:11<00:00,  1.27it/s, loss=4.32, acc=14.9]\nValidation: 100%|██████████| 83/83 [01:03<00:00,  1.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 4.3219, Train Acc: 14.91%\nVal Loss: 3.5653, Val Acc: 25.28%\nSaved best model with accuracy: 25.28%\n\nEpoch 3/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:58<00:00,  1.31it/s, loss=2.75, acc=39.1] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.7543, Train Acc: 39.08%\nVal Loss: 2.9472, Val Acc: 36.10%\nSaved best model with accuracy: 36.10%\n\nEpoch 4/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:07<00:00,  1.28it/s, loss=1.66, acc=63.4] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6623, Train Acc: 63.39%\nVal Loss: 2.7081, Val Acc: 41.18%\nSaved best model with accuracy: 41.18%\n\nEpoch 5/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:01<00:00,  1.30it/s, loss=0.955, acc=79.9]\nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9552, Train Acc: 79.93%\nVal Loss: 2.6540, Val Acc: 44.88%\nSaved best model with accuracy: 44.88%\n\nEpoch 6/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:59<00:00,  1.31it/s, loss=0.531, acc=89.5]\nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5310, Train Acc: 89.52%\nVal Loss: 2.7588, Val Acc: 43.78%\n\nEpoch 7/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:17<00:00,  1.24it/s, loss=0.274, acc=95]   \nValidation: 100%|██████████| 83/83 [01:05<00:00,  1.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2736, Train Acc: 95.00%\nVal Loss: 2.8202, Val Acc: 45.74%\nSaved best model with accuracy: 45.74%\n\nEpoch 8/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:08<00:00,  1.27it/s, loss=0.156, acc=97.6] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1560, Train Acc: 97.61%\nVal Loss: 2.8313, Val Acc: 45.21%\n\nEpoch 9/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:11<00:00,  1.27it/s, loss=0.0988, acc=98.5]\nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0988, Train Acc: 98.45%\nVal Loss: 2.9313, Val Acc: 45.59%\n\nEpoch 10/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:07<00:00,  1.28it/s, loss=0.0692, acc=99.1]\nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0692, Train Acc: 99.12%\nVal Loss: 3.0527, Val Acc: 45.74%\n\nEpoch 11/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:04<00:00,  1.29it/s, loss=0.0718, acc=98.9]\nValidation: 100%|██████████| 83/83 [01:00<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0718, Train Acc: 98.86%\nVal Loss: 2.9944, Val Acc: 44.50%\n\nEpoch 12/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:05<00:00,  1.29it/s, loss=0.07, acc=98.8]  \nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0700, Train Acc: 98.84%\nVal Loss: 3.1608, Val Acc: 44.39%\n\nEpoch 13/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:10<00:00,  1.27it/s, loss=0.072, acc=98.6] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0720, Train Acc: 98.60%\nVal Loss: 3.1729, Val Acc: 44.80%\n\nEpoch 14/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:12<00:00,  1.26it/s, loss=0.0539, acc=99.2]\nValidation: 100%|██████████| 83/83 [01:03<00:00,  1.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0539, Train Acc: 99.18%\nVal Loss: 3.2002, Val Acc: 45.93%\nSaved best model with accuracy: 45.93%\n\nEpoch 15/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:04<00:00,  1.29it/s, loss=0.05, acc=99.1]   \nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0500, Train Acc: 99.08%\nVal Loss: 3.3098, Val Acc: 44.80%\n\nEpoch 16/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:55<00:00,  1.32it/s, loss=0.037, acc=99.3]  \nValidation: 100%|██████████| 83/83 [01:00<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0370, Train Acc: 99.32%\nVal Loss: 3.2328, Val Acc: 44.84%\n\nEpoch 17/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:58<00:00,  1.31it/s, loss=0.0266, acc=99.6] \nValidation: 100%|██████████| 83/83 [00:59<00:00,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0266, Train Acc: 99.63%\nVal Loss: 3.2797, Val Acc: 46.42%\nSaved best model with accuracy: 46.42%\n\nEpoch 18/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:01<00:00,  1.30it/s, loss=0.0245, acc=99.6] \nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0245, Train Acc: 99.63%\nVal Loss: 3.3621, Val Acc: 45.74%\n\nEpoch 19/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:15<00:00,  1.25it/s, loss=0.0215, acc=99.7] \nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0215, Train Acc: 99.67%\nVal Loss: 3.3433, Val Acc: 45.21%\n\nEpoch 20/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:01<00:00,  1.30it/s, loss=0.0214, acc=99.6] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0214, Train Acc: 99.64%\nVal Loss: 3.4157, Val Acc: 46.31%\n\nEpoch 21/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:48<00:00,  1.35it/s, loss=0.0192, acc=99.7] \nValidation: 100%|██████████| 83/83 [01:00<00:00,  1.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0192, Train Acc: 99.67%\nVal Loss: 3.2663, Val Acc: 47.10%\nSaved best model with accuracy: 47.10%\n\nEpoch 22/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:53<00:00,  1.33it/s, loss=0.012, acc=99.9]  \nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0120, Train Acc: 99.87%\nVal Loss: 3.2943, Val Acc: 47.17%\nSaved best model with accuracy: 47.17%\n\nEpoch 23/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:05<00:00,  1.28it/s, loss=0.00825, acc=99.9]\nValidation: 100%|██████████| 83/83 [01:04<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0083, Train Acc: 99.90%\nVal Loss: 3.2844, Val Acc: 47.81%\nSaved best model with accuracy: 47.81%\n\nEpoch 24/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:05<00:00,  1.29it/s, loss=0.00673, acc=99.9]\nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0067, Train Acc: 99.93%\nVal Loss: 3.2730, Val Acc: 46.76%\n\nEpoch 25/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:08<00:00,  1.28it/s, loss=0.00439, acc=100] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0044, Train Acc: 99.95%\nVal Loss: 3.2601, Val Acc: 47.89%\nSaved best model with accuracy: 47.89%\n\nEpoch 26/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:13<00:00,  1.26it/s, loss=0.00419, acc=99.9]\nValidation: 100%|██████████| 83/83 [01:05<00:00,  1.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0042, Train Acc: 99.94%\nVal Loss: 3.2855, Val Acc: 47.93%\nSaved best model with accuracy: 47.93%\n\nEpoch 27/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:08<00:00,  1.28it/s, loss=0.00407, acc=100] \nValidation: 100%|██████████| 83/83 [01:07<00:00,  1.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0041, Train Acc: 99.96%\nVal Loss: 3.3401, Val Acc: 47.78%\n\nEpoch 28/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:06<00:00,  1.28it/s, loss=0.00259, acc=100] \nValidation: 100%|██████████| 83/83 [01:03<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0026, Train Acc: 99.99%\nVal Loss: 3.2853, Val Acc: 47.70%\n\nEpoch 29/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:55<00:00,  1.32it/s, loss=0.00254, acc=100] \nValidation: 100%|██████████| 83/83 [01:01<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0025, Train Acc: 99.98%\nVal Loss: 3.3068, Val Acc: 47.59%\n\nEpoch 30/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:51<00:00,  1.34it/s, loss=0.00204, acc=100] \nValidation: 100%|██████████| 83/83 [00:59<00:00,  1.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0020, Train Acc: 99.99%\nVal Loss: 3.3277, Val Acc: 48.46%\nSaved best model with accuracy: 48.46%\n\nEpoch 31/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:51<00:00,  1.34it/s, loss=0.00196, acc=100] \nValidation: 100%|██████████| 83/83 [01:00<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0020, Train Acc: 99.98%\nVal Loss: 3.2972, Val Acc: 47.59%\n\nEpoch 32/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [05:53<00:00,  1.33it/s, loss=0.00151, acc=100]]\nValidation: 100%|██████████| 83/83 [01:03<00:00,  1.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0015, Train Acc: 100.00%\nVal Loss: 3.2630, Val Acc: 48.38%\n\nEpoch 33/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:05<00:00,  1.29it/s, loss=0.00106, acc=100] \nValidation: 100%|██████████| 83/83 [01:03<00:00,  1.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0011, Train Acc: 100.00%\nVal Loss: 3.2688, Val Acc: 48.15%\n\nEpoch 34/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:05<00:00,  1.28it/s, loss=0.00091, acc=100] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0009, Train Acc: 100.00%\nVal Loss: 3.2603, Val Acc: 48.57%\nSaved best model with accuracy: 48.57%\n\nEpoch 35/40\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 83/83 [01:01<00:00,  1.35it/s] loss=0.000663, acc=100]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0008, Train Acc: 100.00%\nVal Loss: 3.2631, Val Acc: 49.47%\nSaved best model with accuracy: 49.47%\n\nEpoch 36/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:12<00:00,  1.26it/s, loss=0.00104, acc=100] \nValidation: 100%|██████████| 83/83 [01:02<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0010, Train Acc: 99.99%\nVal Loss: 3.2373, Val Acc: 48.83%\n\nEpoch 37/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:07<00:00,  1.28it/s, loss=0.000796, acc=100]\nValidation: 100%|██████████| 83/83 [01:05<00:00,  1.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0008, Train Acc: 100.00%\nVal Loss: 3.2375, Val Acc: 49.17%\n\nEpoch 38/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:14<00:00,  1.25it/s, loss=0.000789, acc=100]\nValidation: 100%|██████████| 83/83 [01:04<00:00,  1.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0008, Train Acc: 99.99%\nVal Loss: 3.2795, Val Acc: 49.25%\n\nEpoch 39/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:05<00:00,  1.28it/s, loss=0.000795, acc=100]\nValidation: 100%|██████████| 83/83 [01:03<00:00,  1.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0008, Train Acc: 100.00%\nVal Loss: 3.2378, Val Acc: 49.17%\n\nEpoch 40/40\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 470/470 [06:13<00:00,  1.26it/s, loss=0.000763, acc=100]\nValidation: 100%|██████████| 83/83 [01:06<00:00,  1.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0008, Train Acc: 100.00%\nVal Loss: 3.2467, Val Acc: 49.21%\n\nLoading best model for inference...\nGenerating predictions...\n","output_type":"stream"},{"name":"stderr","text":"Inference: 100%|██████████| 277/277 [08:26<00:00,  1.83s/it]","output_type":"stream"},{"name":"stdout","text":"\nSubmission saved to submission.csv\nBest validation accuracy: 49.47%\nSample predictions:\n          id_code  sirna\n0  HUVEC-17_1_B03    671\n1  HUVEC-17_1_B04    225\n2  HUVEC-17_1_B05     54\n3  HUVEC-17_1_B06    276\n4  HUVEC-17_1_B07    564\n5  HUVEC-17_1_B08     72\n6  HUVEC-17_1_B09    767\n7  HUVEC-17_1_B10   1015\n8  HUVEC-17_1_B11    292\n9  HUVEC-17_1_B12   1078\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}